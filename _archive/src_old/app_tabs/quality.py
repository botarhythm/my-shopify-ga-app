"""
å“è³ªãƒã‚§ãƒƒã‚¯ã‚¿ãƒ–
ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç›£è¦–ã¨å•é¡Œæ¤œå‡º
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import duckdb
import os
from datetime import datetime, timedelta


def get_db_connection():
    """DuckDBæ¥ç¶šã‚’å–å¾—ï¼ˆèª­å–å°‚ç”¨ï¼‰"""
    db_path = os.getenv("DUCKDB_PATH", "./data/duckdb/commerce.duckdb")
    con = duckdb.connect(db_path, read_only=True)
    con.execute("PRAGMA threads=4; PRAGMA enable_object_cache=true;")
    return con


def run_quality_checks() -> dict:
    """å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
    con = get_db_connection()
    results = {}
    
    try:
        # æ¬ æãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        missing_data = con.execute("""
            SELECT 
                'mart_daily' AS table_name,
                date,
                'Missing sessions' AS issue
            FROM mart_daily 
            WHERE sessions IS NULL
            
            UNION ALL
            
            SELECT 
                'mart_daily' AS table_name,
                date,
                'Missing total_revenue' AS issue
            FROM mart_daily 
            WHERE total_revenue IS NULL
            
            UNION ALL
            
            SELECT 
                'mart_daily' AS table_name,
                date,
                'Missing cost' AS issue
            FROM mart_daily 
            WHERE cost IS NULL
        """).df()
        results["missing_data"] = missing_data
        
        # ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯
        anomalies = con.execute("""
            SELECT 
                date,
                sessions,
                LAG(sessions) OVER (ORDER BY date) AS prev_sessions,
                ABS(sessions - LAG(sessions) OVER (ORDER BY date)) AS change,
                'Large session change' AS issue
            FROM mart_daily
            WHERE ABS(sessions - LAG(sessions) OVER (ORDER BY date)) > 5 * STDDEV(sessions) OVER ()
        """).df()
        results["anomalies"] = anomalies
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        integrity_issues = con.execute("""
            SELECT 
                date,
                roas,
                'Negative ROAS' AS issue
            FROM mart_daily
            WHERE roas < 0
            
            UNION ALL
            
            SELECT 
                date,
                sessions,
                'Sessions less than purchases' AS issue
            FROM mart_daily
            WHERE sessions < purchases
        """).df()
        results["integrity_issues"] = integrity_issues
        
        # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ãƒã‚§ãƒƒã‚¯
        data_freshness = con.execute("""
            SELECT 
                MAX(date) AS latest_date,
                CURRENT_DATE - MAX(date) AS days_old,
                'Data too old' AS issue
            FROM mart_daily
            HAVING CURRENT_DATE - MAX(date) > 1
        """).df()
        results["data_freshness"] = data_freshness
        
        # é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        duplicates = con.execute("""
            SELECT 
                date,
                COUNT(*) AS duplicate_count,
                'Duplicate date records' AS issue
            FROM mart_daily
            GROUP BY date
            HAVING COUNT(*) > 1
        """).df()
        results["duplicates"] = duplicates
        
        # ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        completeness = con.execute("""
            SELECT 
                'stg_ga4' AS table_name,
                COUNT(*) AS record_count,
                MIN(date) AS min_date,
                MAX(date) AS max_date
            FROM stg_ga4
            
            UNION ALL
            
            SELECT 
                'stg_shopify_orders' AS table_name,
                COUNT(*) AS record_count,
                MIN(created_at) AS min_date,
                MAX(created_at) AS max_date
            FROM stg_shopify_orders
            
            UNION ALL
            
            SELECT 
                'stg_square_payments' AS table_name,
                COUNT(*) AS record_count,
                MIN(created_at) AS min_date,
                MAX(created_at) AS max_date
            FROM stg_square_payments
            
            UNION ALL
            
            SELECT 
                'stg_ads_campaign' AS table_name,
                COUNT(*) AS record_count,
                MIN(date) AS min_date,
                MAX(date) AS max_date
            FROM stg_ads_campaign
        """).df()
        results["completeness"] = completeness
        
    finally:
        con.close()
    
    return results


def render_quality_summary(results: dict):
    """å“è³ªã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    st.subheader("ğŸ“Š å“è³ªã‚µãƒãƒªãƒ¼")
    
    # å•é¡Œã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    total_issues = (
        len(results.get("missing_data", [])) +
        len(results.get("anomalies", [])) +
        len(results.get("integrity_issues", [])) +
        len(results.get("data_freshness", [])) +
        len(results.get("duplicates", []))
    )
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ç·å•é¡Œæ•°",
            value=total_issues,
            delta=None
        )
    
    with col2:
        missing_count = len(results.get("missing_data", []))
        st.metric(
            label="æ¬ æãƒ‡ãƒ¼ã‚¿",
            value=missing_count,
            delta=None
        )
    
    with col3:
        anomaly_count = len(results.get("anomalies", []))
        st.metric(
            label="ç•°å¸¸å€¤",
            value=anomaly_count,
            delta=None
        )
    
    with col4:
        integrity_count = len(results.get("integrity_issues", []))
        st.metric(
            label="æ•´åˆæ€§å•é¡Œ",
            value=integrity_count,
            delta=None
        )
    
    # å“è³ªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    if total_issues == 0:
        st.success("âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªã¯è‰¯å¥½ã§ã™")
    elif total_issues <= 5:
        st.warning("âš ï¸ è»½å¾®ãªå“è³ªå•é¡ŒãŒã‚ã‚Šã¾ã™")
    else:
        st.error("âŒ é‡å¤§ãªå“è³ªå•é¡ŒãŒã‚ã‚Šã¾ã™")


def render_missing_data_analysis(results: dict):
    """æ¬ æãƒ‡ãƒ¼ã‚¿åˆ†æã‚’è¡¨ç¤º"""
    st.subheader("ğŸ” æ¬ æãƒ‡ãƒ¼ã‚¿åˆ†æ")
    
    missing_data = results.get("missing_data", [])
    
    if missing_data.empty:
        st.success("âœ… æ¬ æãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    # æ¬ æãƒ‡ãƒ¼ã‚¿ã®è©³ç´°
    st.warning(f"âš ï¸ {len(missing_data)}ä»¶ã®æ¬ æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    
    # æ¬ æãƒ‡ãƒ¼ã‚¿ã®ãƒ†ãƒ¼ãƒ–ãƒ«
    st.dataframe(missing_data, use_container_width=True)
    
    # æ¬ æãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒ
    if not missing_data.empty:
        fig = px.histogram(
            missing_data,
            x="date",
            title="æ¬ æãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜åˆ†å¸ƒ",
            labels={"date": "æ—¥ä»˜", "count": "æ¬ æä»¶æ•°"}
        )
        st.plotly_chart(fig, use_container_width=True)


def render_anomaly_analysis(results: dict):
    """ç•°å¸¸å€¤åˆ†æã‚’è¡¨ç¤º"""
    st.subheader("ğŸ“ˆ ç•°å¸¸å€¤åˆ†æ")
    
    anomalies = results.get("anomalies", [])
    
    if anomalies.empty:
        st.success("âœ… ç•°å¸¸å€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    st.warning(f"âš ï¸ {len(anomalies)}ä»¶ã®ç•°å¸¸å€¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    
    # ç•°å¸¸å€¤ã®è©³ç´°
    st.dataframe(anomalies, use_container_width=True)
    
    # ç•°å¸¸å€¤ã®æ¨ç§»
    if not anomalies.empty:
        fig = px.scatter(
            anomalies,
            x="date",
            y="sessions",
            title="ç•°å¸¸å€¤ã®æ¨ç§»",
            labels={"date": "æ—¥ä»˜", "sessions": "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°"}
        )
        st.plotly_chart(fig, use_container_width=True)


def render_integrity_analysis(results: dict):
    """æ•´åˆæ€§åˆ†æã‚’è¡¨ç¤º"""
    st.subheader("ğŸ”— ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§åˆ†æ")
    
    integrity_issues = results.get("integrity_issues", [])
    
    if integrity_issues.empty:
        st.success("âœ… æ•´åˆæ€§å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    st.error(f"âŒ {len(integrity_issues)}ä»¶ã®æ•´åˆæ€§å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    
    # æ•´åˆæ€§å•é¡Œã®è©³ç´°
    st.dataframe(integrity_issues, use_container_width=True)


def render_data_freshness_analysis(results: dict):
    """ãƒ‡ãƒ¼ã‚¿é®®åº¦åˆ†æã‚’è¡¨ç¤º"""
    st.subheader("â° ãƒ‡ãƒ¼ã‚¿é®®åº¦åˆ†æ")
    
    data_freshness = results.get("data_freshness", [])
    
    if data_freshness.empty:
        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã¯æœ€æ–°ã§ã™")
        return
    
    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå¤ããªã£ã¦ã„ã¾ã™")
    
    # ãƒ‡ãƒ¼ã‚¿é®®åº¦ã®è©³ç´°
    st.dataframe(data_freshness, use_container_width=True)


def render_completeness_analysis(results: dict):
    """ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§åˆ†æã‚’è¡¨ç¤º"""
    st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§åˆ†æ")
    
    completeness = results.get("completeness", [])
    
    if completeness.empty:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
    fig = px.bar(
        completeness,
        x="table_name",
        y="record_count",
        title="å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°",
        labels={"table_name": "ãƒ†ãƒ¼ãƒ–ãƒ«å", "record_count": "ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°"}
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã®å¯è¦–åŒ–
    if not completeness.empty:
        # æ—¥ä»˜ç¯„å›²ã‚’å¯è¦–åŒ–
        date_ranges = []
        for _, row in completeness.iterrows():
            if pd.notna(row["min_date"]) and pd.notna(row["max_date"]):
                date_ranges.append({
                    "table_name": row["table_name"],
                    "start_date": row["min_date"],
                    "end_date": row["max_date"]
                })
        
        if date_ranges:
            date_df = pd.DataFrame(date_ranges)
            fig = px.timeline(
                date_df,
                x_start="start_date",
                x_end="end_date",
                y="table_name",
                title="ãƒ‡ãƒ¼ã‚¿ç¯„å›²",
                labels={"table_name": "ãƒ†ãƒ¼ãƒ–ãƒ«å", "start_date": "é–‹å§‹æ—¥", "end_date": "çµ‚äº†æ—¥"}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # å®Œå…¨æ€§è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
    st.dataframe(completeness, use_container_width=True)


def render_quality_tab():
    """å“è³ªãƒã‚§ãƒƒã‚¯ã‚¿ãƒ–ã‚’è¡¨ç¤º"""
    st.header("ğŸ” ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯")
    
    # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸ”„ å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"):
        with st.spinner("å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­..."):
            results = run_quality_checks()
            st.session_state.quality_results = results
        st.success("å“è³ªãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    # çµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è¡¨ç¤º
    if "quality_results" in st.session_state:
        results = st.session_state.quality_results
        
        # å“è³ªã‚µãƒãƒªãƒ¼
        render_quality_summary(results)
        
        st.divider()
        
        # è©³ç´°åˆ†æ
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "æ¬ æãƒ‡ãƒ¼ã‚¿", "ç•°å¸¸å€¤", "æ•´åˆæ€§", "ãƒ‡ãƒ¼ã‚¿é®®åº¦", "å®Œå…¨æ€§"
        ])
        
        with tab1:
            render_missing_data_analysis(results)
        
        with tab2:
            render_anomaly_analysis(results)
        
        with tab3:
            render_integrity_analysis(results)
        
        with tab4:
            render_data_freshness_analysis(results)
        
        with tab5:
            render_completeness_analysis(results)
    
    else:
        st.info("ã€Œå“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å“è³ªãƒã‚§ãƒƒã‚¯ã‚’é–‹å§‹ã—ã¦ãã ã•ã„")
